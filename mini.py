import streamlit as st
from langchain_ollama import ChatOllama
from langchain_core.messages import AIMessage, HumanMessage
from collections import deque

# Ollama modelini baÅŸlat
llm = ChatOllama(model="mistral")  # Model adÄ±nÄ± kendi sistemine gÃ¶re deÄŸiÅŸtir

# Mesaj geÃ§miÅŸini tutmak iÃ§in
chat_history = deque()


def stream_chat_response(user_message):
    """LLM ile stream modunda sohbet gerÃ§ekleÅŸtirir."""
    chat_history.append(HumanMessage(content=user_message))  # KullanÄ±cÄ± mesajÄ±nÄ± kaydet

    messages = [
        {"role": "user" if isinstance(msg, HumanMessage) else "assistant", "content": msg.content}
        for msg in chat_history
    ]

    response_placeholder = st.empty()  # Stream iÃ§in boÅŸ bir alan oluÅŸtur
    full_response = ""

    # Ollama'dan yanÄ±tlarÄ± stream modunda al
    for chunk in llm.stream(messages):
        full_response += chunk.content  # HATA BURADAYDI: chunk["message"] yerine chunk.content
        response_placeholder.write(full_response)  # Gelen kÄ±smÄ± ekrana yaz

    chat_history.append(AIMessage(content=full_response))  # YanÄ±tÄ± kaydet


# **Streamlit ArayÃ¼zÃ¼**
st.title("Chatbot (Streamlit + Ollama)")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# GeÃ§miÅŸ mesajlarÄ± ekrana yazdÄ±r
for msg in st.session_state.chat_history:
    role = "ğŸ‘¤ You" if isinstance(msg, HumanMessage) else "ğŸ¤– AI"
    st.markdown(f"**{role}:** {msg.content}")

# KullanÄ±cÄ±dan mesaj al
user_input = st.text_input("Enter your message:")

if st.button("Send") and user_input:
    stream_chat_response(user_input)
    st.session_state.chat_history = chat_history  # GÃ¼ncellenmiÅŸ geÃ§miÅŸi sakla
